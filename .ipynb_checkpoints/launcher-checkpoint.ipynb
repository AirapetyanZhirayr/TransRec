{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from myTransRec import TransRec\n",
    "from myDataPreprocessing import train_test_split, preprocess_data, get_batches\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 20000\n",
    "BATCH_SIZE = 1024\n",
    "LAMBDA = 0.05\n",
    "NUM_SAMPLED = 16\n",
    "dfPath = '/Users/jiji/RS_project/df_cutted.csv'\n",
    "data, id2user, user2id, id2poi, poi2id = preprocess_data(dfPath)\n",
    "n_users = len(id2user); n_poi = len(id2poi)\n",
    "\n",
    "train_data, test_data = train_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransRec(EMBEDDING_DIM, user2id, id2user, poi2id, id2poi)\n",
    "criterion = nn.LogSigmoid()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=LAMBDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/20000] Batch: [200/1162]\n",
      "Epoch: [1/20000] Batch: [400/1162]\n",
      "Epoch: [1/20000] Batch: [600/1162]\n",
      "Epoch: [1/20000] Batch: [800/1162]\n",
      "Epoch: [1/20000] Batch: [1000/1162]\n",
      "At Epoch: [1/20000] [Loss]: [383.05970507860184]\n",
      "\n",
      "Epoch: [2/20000] Batch: [200/1162]\n",
      "Epoch: [2/20000] Batch: [400/1162]\n",
      "Epoch: [2/20000] Batch: [600/1162]\n",
      "Epoch: [2/20000] Batch: [800/1162]\n",
      "Epoch: [2/20000] Batch: [1000/1162]\n",
      "At Epoch: [2/20000] [Loss]: [245.5910206735134]\n",
      "\n",
      "Epoch: [3/20000] Batch: [200/1162]\n",
      "Epoch: [3/20000] Batch: [400/1162]\n",
      "Epoch: [3/20000] Batch: [600/1162]\n",
      "Epoch: [3/20000] Batch: [800/1162]\n",
      "Epoch: [3/20000] Batch: [1000/1162]\n",
      "At Epoch: [3/20000] [Loss]: [187.8947517797351]\n",
      "\n",
      "Epoch: [4/20000] Batch: [200/1162]\n",
      "Epoch: [4/20000] Batch: [400/1162]\n",
      "Epoch: [4/20000] Batch: [600/1162]\n",
      "Epoch: [4/20000] Batch: [800/1162]\n",
      "Epoch: [4/20000] Batch: [1000/1162]\n",
      "At Epoch: [4/20000] [Loss]: [163.8016004115343]\n",
      "\n",
      "Epoch: [5/20000] Batch: [200/1162]\n",
      "Epoch: [5/20000] Batch: [400/1162]\n",
      "Epoch: [5/20000] Batch: [600/1162]\n",
      "Epoch: [5/20000] Batch: [800/1162]\n",
      "Epoch: [5/20000] Batch: [1000/1162]\n",
      "At Epoch: [5/20000] [Loss]: [156.80735386908054]\n",
      "\n",
      "Epoch: [6/20000] Batch: [200/1162]\n",
      "Epoch: [6/20000] Batch: [400/1162]\n",
      "Epoch: [6/20000] Batch: [600/1162]\n",
      "Epoch: [6/20000] Batch: [800/1162]\n",
      "Epoch: [6/20000] Batch: [1000/1162]\n",
      "At Epoch: [6/20000] [Loss]: [154.10379387810826]\n",
      "\n",
      "Epoch: [7/20000] Batch: [200/1162]\n",
      "Epoch: [7/20000] Batch: [400/1162]\n",
      "Epoch: [7/20000] Batch: [600/1162]\n",
      "Epoch: [7/20000] Batch: [800/1162]\n",
      "Epoch: [7/20000] Batch: [1000/1162]\n",
      "At Epoch: [7/20000] [Loss]: [153.95180074125528]\n",
      "\n",
      "Epoch: [8/20000] Batch: [200/1162]\n",
      "Epoch: [8/20000] Batch: [400/1162]\n",
      "Epoch: [8/20000] Batch: [600/1162]\n",
      "Epoch: [8/20000] Batch: [800/1162]\n",
      "Epoch: [8/20000] Batch: [1000/1162]\n",
      "At Epoch: [8/20000] [Loss]: [153.77074091881514]\n",
      "\n",
      "Epoch: [9/20000] Batch: [200/1162]\n",
      "Epoch: [9/20000] Batch: [400/1162]\n",
      "Epoch: [9/20000] Batch: [600/1162]\n",
      "Epoch: [9/20000] Batch: [800/1162]\n",
      "Epoch: [9/20000] Batch: [1000/1162]\n",
      "At Epoch: [9/20000] [Loss]: [154.1103345118463]\n",
      "\n",
      "Epoch: [10/20000] Batch: [200/1162]\n",
      "Epoch: [10/20000] Batch: [400/1162]\n",
      "Epoch: [10/20000] Batch: [600/1162]\n",
      "Epoch: [10/20000] Batch: [800/1162]\n",
      "Epoch: [10/20000] Batch: [1000/1162]\n",
      "At Epoch: [10/20000] [Loss]: [154.20807567238808]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-a13a60410d4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0m_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0m_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0m_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(EPOCHS):\n",
    "\n",
    "    batches = list(get_batches(train_data, BATCH_SIZE, NUM_SAMPLED, model.n_poi))\n",
    "    step = 0\n",
    "    batch_num = len(batches)\n",
    "    loss = .0\n",
    "    for batch in batches:\n",
    "        user_id, prev_id, pos_id, neg_id = map(torch.LongTensor, batch)\n",
    "        optimizer.zero_grad()\n",
    "        objective = model(user_id, prev_id, pos_id, neg_id)\n",
    "        _loss = - criterion(objective).sum()\n",
    "        _loss.backward()\n",
    "        optimizer.step()\n",
    "        loss+=_loss.data.numpy()\n",
    "\n",
    "        step+=1\n",
    "        if step%200 == 0:\n",
    "            print(\"Epoch: [{}/{}] Batch: [{}/{}]\".format(i+1, EPOCHS, step, batch_num))\n",
    "    print(\"At Epoch: [{}/{}] [Loss]: [{}]\\n\".format(i+1, EPOCHS, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16275/16275 [00:09<00:00, 1729.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2513056835637481\n",
      "0.2572657450076805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# HIT@k\n",
    "from tqdm import tqdm\n",
    "k = 20\n",
    "k_most_pop = df.sort_values(ascending=False).keys()[:k].to_numpy()\n",
    "k_most_pop = np.array(list(map(lambda x: poi2id[x], k_most_pop.tolist())))\n",
    "hitTrans = []\n",
    "hitPop = []\n",
    "for user in tqdm(test_data):\n",
    "    prev, ground = test_data[user][0]\n",
    "    hitTrans.append(ground in model.predict(user, prev)[:k])\n",
    "    hitPop.append(ground in k_most_pop)\n",
    "    \n",
    "print(np.array(hitTrans).mean())\n",
    "print(np.array(hitPop).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/jiji/Desktop/GitHub/TransRec/data/dataPartitioned.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_train,user_validation,user_test, usernum,itemnum = np.load(path, allow_pickle=True)\n",
    "del user_train, user_validation, user_test, usernum, itemnum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Их алгоритм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_data_path = '/Users/jiji/Desktop/GitHub/TransRec/src/meta_data.npy'\n",
    "dataset=np.load(orig_data_path, allow_pickle=True)\n",
    "\n",
    "([User,\n",
    "  # Item,\n",
    "  usermap,\n",
    "  itemmap,\n",
    "  usernum,\n",
    "  itemnum])\\\n",
    "    =dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', n_neighbors=50)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userVecPath = '/Users/jiji/Desktop/GitHub/TransRec/src/userVector.npy'\n",
    "itemVecPath = '/Users/jiji/Desktop/GitHub/TransRec/src/itemVector.npy'\n",
    "itemBiasPath = '/Users/jiji/Desktop/GitHub/TransRec/src/itemBias.npy'\n",
    "userGlobalPath = '/Users/jiji/Desktop/GitHub/TransRec/src/userGlobal.npy'\n",
    "\n",
    "userGlobal = np.load(userGlobalPath)\n",
    "userVec = np.load(userVecPath)\n",
    "itemVec = np.load(itemVecPath)\n",
    "itemBias = np.load(itemBiasPath)\n",
    "itemBias = - itemBias\n",
    "itemBias = np.sqrt(itemBias.max() - itemBias)\n",
    "itemVecB = np.c_[itemVec, itemBias]\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "KNN = NearestNeighbors(n_neighbors=50, algorithm='ball_tree')\n",
    "KNN.fit(itemVecB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2user_orig = {val:key for key, val in usermap.items()}\n",
    "id2poi_orig = {val:key for key, val in itemmap.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orig_predict(user_id, pre_poi):\n",
    "    z = itemVec[pre_poi]+userVec[user_id] + userGlobal\n",
    "    z = np.append(z, 0)\n",
    "    return z\n",
    "    _, indices = KNN.kneighbors(z)\n",
    "    indices = indices[0]\n",
    "    indices = indices[indices!=int(pre_poi[0])]\n",
    "    indices\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0618728 , -0.01778378, -0.13878452,  0.18108239,  0.098137  ,\n",
       "       -0.17070477,  0.00215543, -0.05198784,  0.14655683,  0.01327071])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemVec[pre_poi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10241,)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_predict(user_id, pre_poi).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16275 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 0.43706142  0.10619391 -0.03068581  0.45146024 -0.03199269 -0.18452884\n  0.05187626  0.14735546  0.39370056 -0.10141635  0.        ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-272-60df05032877>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mhitTrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mhitPop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk_most_pop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mhitOrig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_ground\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morig_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_prev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhitTrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-271-c8602e2333e4>\u001b[0m in \u001b[0;36morig_predict\u001b[0;34m(user_id, pre_poi)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitemVec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpre_poi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0muserVec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0muserGlobal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_poi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    604\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_precomputed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0mquery_is_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    620\u001b[0m                     \u001b[0;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 0.43706142  0.10619391 -0.03068581  0.45146024 -0.03199269 -0.18452884\n  0.05187626  0.14735546  0.39370056 -0.10141635  0.        ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# HIT@k\n",
    "from tqdm import tqdm\n",
    "k = 20\n",
    "k_most_pop = df.sort_values(ascending=False).keys()[:k].to_numpy()\n",
    "k_most_pop = np.array(list(map(lambda x: poi2id[x], k_most_pop.tolist())))\n",
    "hitTrans = []\n",
    "hitPop = []\n",
    "hitOrig = []\n",
    "for user in tqdm(test_data):\n",
    "    orig_user = usermap[id2user_orig[user]]\n",
    "    \n",
    "    prev, ground = test_data[user][0]\n",
    "    orig_prev = itemmap[id2poi_orig[prev]]\n",
    "    orig_ground = itemmap[id2poi_orig[ground]]\n",
    "    \n",
    "    hitTrans.append(ground in model.predict(user, prev)[:k])\n",
    "    hitPop.append(ground in k_most_pop)\n",
    "    hitOrig.append(orig_ground in orig_predict(orig_user, orig_prev))\n",
    "    \n",
    "print(np.array(hitTrans).mean())\n",
    "print(np.array(hitPop).mean())\n",
    "print(np.array(hitOrig).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
